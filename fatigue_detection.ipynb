{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fatigue Detection Using Facial Landmarks and ANN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Input : coordinates (x,y) of face landmarks \n",
    "## Output : Fatigue level\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "### Import data analyse class for cacluls parameter from landamrks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analyse import AnalyseData\n",
    "from format_data import DataFormator"
   ]
  },
  {
   "source": [
    "### Define Path of csv data and video infos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"DESFAM_Semaine 2-Vendredi_PVT_H64\"\n",
    "video_infos_path = \"data/stage_data_out/videos_infos.csv\"\n",
    "video_path = \"data/stage_data_out/DESFAM_Semaine 2-Vendredi_PVT_H64_hog.csv\""
   ]
  },
  {
   "source": [
    "### Append Measure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'measure': 'ear', 'axis_x': 'frame'}]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "analyse_data = AnalyseData(video_path)\n",
    "analyse_data.measure_ear()"
   ]
  },
  {
   "source": [
    "Show fourier transformation pass bas filter ect"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of ear > 0.4\n      frame     ear_l     ear_r       ear\n0         0  0.387097  0.415926  0.401511\n1         1  0.403226  0.385297  0.394261\n2         2  0.401164  0.399806  0.400485\n3         3  0.387566  0.399806  0.393686\n5         5  0.387566  0.387566  0.387566\n6         6  0.387566  0.387633  0.387599\n8         8  0.383930  0.400693  0.392312\n9         9  0.400497  0.400000  0.400249\n1361   1435  0.367363  0.414243  0.390803\n1362   1436  0.366609  0.397108  0.381858\n1364   1438  0.378412  0.397108  0.387760\n1366   1440  0.370928  0.414243  0.392586\n1370   1444  0.383813  0.400497  0.392155\n1378   1452  0.379867  0.383239  0.381553\n1381   1455  0.383813  0.401164  0.392489\n1384   1458  0.367363  0.414243  0.390803\n1387   1461  0.366609  0.414243  0.390426\n2513   2587  0.380648  0.379867  0.380257\n"
     ]
    }
   ],
   "source": [
    "ear = analyse_data.df_measure\n",
    "print(\"Number of ear > 0.4\")\n",
    "print(ear[ear[\"ear\"]>0.38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Append Label"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ear = DataFormator.make_label_df(num_min = 5, video_name = video_name, df_measure= analyse_data.df_measure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_ear)\n",
    "df_temporal, df_label = DataFormator.make_df_temporal_label([10,20,30,40,50],df_ear)\n",
    "df_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df_temporal, df_label = DataFormator.make_df_temporal_label([10],df_ear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tab = DataFormator.make_df_feature(df_temporal, df_label, [10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_tab : \n",
    "    DataFormator.save_df(df, video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = DataFormator.convert_df_temporal_array_into_df(ear_df)"
   ]
  }
 ]
}